{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center><h1><strong> Informe Tarea 1 - Beer Clustering </strong></h1></center>\n",
    "\n",
    "<center><h3> Matías Pacheco &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;201204619-k</h3></center>\n",
    "<center><h3> Juan Pablo Castillo Vera &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 201204595-9</h3></center>\n",
    "\n",
    "## Descripción del dataset\n",
    "\n",
    "El dataset Beer Reviews es una colección de 1.590.892 críticas de cervezas que se encuentran disponibles en el sitio http://beeradvocate.com/. Éstas críticas toman en consideración características como aroma, apariencia y sabor para asignarle un puntaje a la cerveza que está siendo evaluada.\n",
    "\n",
    "Cada registro del dataset completo está compuesto por las siguientes columnas:\n",
    "\n",
    "|Columna             |Significado            |Tipo       |\n",
    "|---                 |---                    |---        |\n",
    "|brewery_id          |ID cervecería          |Numérico   |\n",
    "|brewery_name        |Nombre Cervecería      |Texto      |\n",
    "|review_time         |Tiempo de evaluación   |Numérico   |\n",
    "|review_overall      |Puntaje del review     |Numérico   |\n",
    "|review_aroma        |Puntaje aroma          |Numérico   |\n",
    "|review_appearence   |Puntaje apariencia     |Numérico   |\n",
    "|review_profilename  |Nombre del evaluador   |Texto      |\n",
    "|beer_style          |Tipo de cerveza        |Texto      |\n",
    "|review_palate       |Puntaje paladar        |Numérico   |\n",
    "|review_taste        |Puntaje gusto          |Numérico   |\n",
    "|beer_abv            |Grado alcohólico       |Numérico   |\n",
    "|beer_beerid         |ID cerveza             |Numérico   |\n",
    "\n",
    "Cabe señalar que como pre-procesamiento de los datos, se setearon en cero todos aquellos campos numéricos del dataset que estuvieran vacíos (string '').\n",
    "\n",
    "\n",
    "## Análisis de Clustering\n",
    "\n",
    "Se realizará un análisis de clustering con el dataset con cada uno de los siguientes cinco algoritmos:\n",
    "* K-Means\n",
    "* Minibatch K-Means\n",
    "* HAC Complete\n",
    "* Ward\n",
    "* DBScan\n",
    "\n",
    "### Observaciones y Supuestos\n",
    "\n",
    "* Antes del procesamiento de los datos, éstos fueron normalizados BLABLABLABLBALBALBALBALBALBALBALBLBA.. JP DO YOUR THING!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "...\n",
    "reviews = StandardScaler().fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para reducir la dimensionalidad de los vectores, y posteriormente poder graficar los resultados en un minifold 2D, se utilizó Principal Component Analysis (PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "dataset = pd.read_csv('beer_reviews.csv')\n",
    "...\n",
    "reviews = PCA(n_components = 2).fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se tomaron los campos **brewery_id** y **beer_beerid** como las formas numéricas de las etiquetas **brewery_name** y **beer_type**. De esta forma, **brewery_id** es equivalente a **brewery_name**, y **beer_beerid** es equivalente a **beer_type**. \n",
    "\n",
    "* Todos los análisis que se muestran a continuación se realizaron entrenando los algoritmos de clustering con las siguientes 6 variables enteras del dataset: review_overall, review_aroma, review_appearance, review_palate, review_taste, beer_abv. Las demás variables no numéricas fueron descartadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.DataFrame({'review_overall':dataset['review_overall'], 'review_aroma':dataset['review_aroma'], 'review_appearance':dataset['review_appearance'], 'review_palate':dataset['review_palate'], 'review_taste':dataset['review_taste'],'beer_abv':dataset['beer_abv']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dado que los a los algortimos no se les pasa como parte del dataset las etiquetas que se quieren evaluar, éste proceso de clustering es no supervisado. Es por esto que posterior a la ejecución de los algoritmos de clustering se evalúa la calidad de los clusters encontrados utilizando la función Normalized Mutual Information (NMI), a la cual se le pasa como parámetro las etiquetas reales y las etiquetas obtenidas por los algoritmos, retornando un valor entre 0 y 1 que determina la calidad de los clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "...\n",
    "labels = list(clustering_algorithm.labels_)\n",
    "NMI(real_labels, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En este informe se mostrarán sólo los gráficos resultantes del análisis del dataset con cada algoritmo. El código fuente está disponible en https://github.com/matipacheco/Tarea1-MD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means\n",
    "\n",
    "Los parámetros de K-Means utilizados para realizar el análisis fueron los siguientes:\n",
    "\n",
    "* **init     = 'k-means++'**. Para una convergencia más rápida.\n",
    "* **n_init   = 10**. Se comprobó que incrementar la cantidad de veces que se ejecuta el algoritmo no mejora significativamente el resultado, sólo se produce un pequeño cambio en la posición de los centroides.\n",
    "* **max_iter = 300 (default)**. Se comprobó que incrementar la cantidad máxima de iteraciones del algoritmo no mejora el resultado.\n",
    "\n",
    "Los demás parámetros se dejaron en su valor por default, ya que la modificación de éstos no produjeron cambios significativos en los resultados obtenidos.\n",
    "\n",
    "Es importante destacar que se puede determinar la cantidad óptima de clusters verificando el valor obtenido por la evaluación NMI. Índices más grandes indican mejores valores de k. \n",
    "\n",
    "Dicho lo anterior, se ejecutó el algoritmo K-Means múltiples veces, probando con distintos valores para el parámetro k, con valores desde k = 2 hasta k = 100 clusters. Para la etiqueta **beer_beerid** con **k = 98** se obtiene el mejor índice NMI, NMI = 0.3003. Del mismo modo, para la etiqueta **brewery_id** también se tiene una cantidad óptima de clusters **k = 98**, con un índice NMI =  0.1299.\n",
    "\n",
    "A continuación se muestra la imagen que resulta de la ejecución K-Means con 98 clusters. \n",
    "\n",
    "<center><img src=\"PlotsKMeans/kmeans.png\"></center>\n",
    "<center><small>Figura 1: Clustering utilizando K-Means.</small></center>\n",
    "\n",
    "\n",
    "### Minibatch K-Means\n",
    "\n",
    "Los parámetros de Minibatch K-Means utilizados para realizar el análisis fueron los siguientes:\n",
    "\n",
    "* **n_init   = 100**. Se comprobó que incrementar la cantidad de veces que se ejecuta el algoritmo produce mejoras en el posicionamiento de los centroides.\n",
    "* **batch_size = 1000**. Se comprobó que incrementar el tamaño de los batches, mejora el posicionamiento de los centroides de los clusters, pero para valores mayores a 1000 este cambio es muy poco significativo.\n",
    "\n",
    "Los demás parámetros se dejaron en su valor por default, ya que la modificación de éstos no produjeron cambios significativos en los resultados obtenidos.\n",
    "\n",
    "Al igual que para K-Means, se ejecutó Minibatch K-Means con k = 2 hasta k = 100. En este caso, para la etiqueta **beer_beerid** se tiene una cantidad óptima de clusters **k = 100**, con un índice NMI = 0.2998. Mientras que para la etiqueta **brewery_id** se tiene un índice NMI máximo igual a 0.1299, utilizando la misma cantidad de clusters.\n",
    "\n",
    "A continuación se muestra la imagen que resulta de la ejecución Minibatch K-Means con 100 clusters. \n",
    "\n",
    "<center><img src=\"PlotsMinibatchKMeans/minibatch.png\"></center>\n",
    "<center><small>Figura 2: Clustering utilizando Minibatch K-Means.</small></center>\n",
    "\n",
    "\n",
    "### HAC Complete\n",
    "\n",
    "En primer lugar, es necesario aclarar que para realizar los análisis con el algoritmo HAC, se utilizó un subconjunto de 20.000 elementos del dataset, a diferencia de los dos algoritmos anteriores en los que se analizó el dataset completo. Esto se debe a que para un número mayor de elementos la ejecución del algoritmo consume muchísimos recursos del computador, y por falta de memoria y de componentes hardware más poderosas, el algoritmo siempre terminaba cayéndose.\n",
    "\n",
    "Los parámetros de HAC utilizados para realizar el análisis fueron los siguientes:\n",
    "\n",
    "* **linkage   = 'complete'**. Por restricción de la tarea.\n",
    "* **affinity = 'euclidean'**. Se comprobó que sólo con la métrica cosine se obtenían clusters distintos. Las métricas euclidean, manhattan, l1 y l2 formaban los mismos clusters.\n",
    "\n",
    "Los demás parámetros se dejaron en su valor por default, ya que la modificación de éstos no produjeron cambios significativos en los resultados obtenidos.\n",
    "\n",
    "Al igual que los dos algoritmos anteriores, se ejecutó HAC pasándole como parámetro valores de k = 2 hasta k = 100. En este caso, para la etiqueta **beer_beerid** se tiene una cantidad óptima de clusters **k = 100**, con un índice NMI = 0.4227. Mientras que para la etiqueta **brewery_id** se tiene un índice NMI máximo igual a 0.2332, para **k = 98** clusters. Se puede apreciar claramente que este algoritmo retorna valores de NMI mucho mejores que K-Means y Minibatch K-Means, pero no se puede asegurar que efectivamente HAC sea mejor que los otros dos, dado que el algoritmo se probó con un subset correspondiente al 0.01% del total de datos.\n",
    "\n",
    "Sin embargo, hay que destacar que para este algoritmo, y a diferencia de los dos anteriores, para cada atiqueta se obtuvieron valores distintos de k. Dicho eso, a continuación se muestra la imagen que resulta de la ejecución de  HAC con 98 y con 100 clusters.\n",
    "\n",
    "<center><img src=\"PlotsHAC/hac98.png\"></center>\n",
    "<center><small>Figura 3: Clustering utilizando HAC con 98 clusters.</small></center>\n",
    "\n",
    "<center><img src=\"PlotsHAC/hac100.png\"></center>\n",
    "<center><small>Figura 4: Clustering utilizando HAC con 100 clusters.</small></center>\n",
    "\n",
    "\n",
    "### Ward\n",
    "\n",
    "Antes de comenzar el analisis, es necesario aclarar que el algoritmo Ward solo se pudo utilizar un subconjunto de 9.000 elementos del dataset. Esto se debe a que para un número mayor de elementos la ejecución del algoritmo consume muchísimos recursos del computador, y por falta de hardware y memoria el algoritmo siempre terminaba cayéndose. Por lo que para obtener resultados, se utiliza una muestra poco significativa (9.000 de 1.590.892 datos).\n",
    "\n",
    "A continuación se muestran los resultados del clustering por *brewery_id* para 2, 3, 4 y 5 clusters:\n",
    "\n",
    "<center><img src=\"PlotsWard/ward1.png\"></center>\n",
    "<center><small>Figura 8: Clustering por brewery_id utilizando Ward para 2, 3, 4 y 5 clusters.</small></center>\n",
    "\n",
    "Como puede verse, la separacion entre los clusters es poco notoria, pero comparando los 4 resultados, con k = 4 se nota la mejor separacion de los datos.\n",
    "\n",
    "A continuación se muestran los resultados del clustering por *beer_beerid* para 2, 3, 4 y 5 clusters:\n",
    "\n",
    "<center><img src=\"PlotsWard/ward2.png\"></center>\n",
    "<center><small>Figura 9: Clustering por beer_beerid utilizando Ward para 2, 3, 4 y 5 clusters.</small></center>\n",
    "\n",
    "Al igual que con la otra etiqueta, la separacion entre clusters sigue siendo poco notoria. Pero con k = 3 se nota la mejor separacion de los datos, por lo tanto, con la etiqueta brewery_id existen 4 clusters y con la etiqueta beer_beerid existen 3 clusters.\n",
    "\n",
    "### DBScan\n",
    "\n",
    "\n",
    "Para DBScan, solo se logro utilizar un subconjunto de 150.000 elementos del dataset por problemas de memoria y hardware similares que cuando se utilizo HAC.\n",
    "\n",
    "Los parámetros de DBScan utilizados para realizar el análisis fueron los siguientes:\n",
    "\n",
    "* **eps   = 0.5**. Para tener un radio maximo bueno y facilitar la generacion de core points.\n",
    "* **min_samples = 30**. Se comprobo experimentando que este es un valor estable para alcanzar un buen numero de clusters.\n",
    "\n",
    "Los demás parámetros se dejaron en su valor por default, ya que la modificación de éstos no produjeron cambios significativos en los resultados obtenidos. A continuacion se mostraran los graficos haciendo diferencia por color de los clusters y por tamaño (circulos mas grandes son *Core Points* y los puntos negros son *Noisy Points*). \n",
    "\n",
    "El resultado para ambas etiquetas fueron los siguientes:\n",
    "\n",
    "<center><img src=\"PlotsDBScan/dbscan_etiqueta1_1.png\"></center>\n",
    "<center><small>Figura 10: Clustering por brewery_id utilizando DBScan.</small></center>\n",
    "\n",
    "Como puede notarse, hay bastante Noisy Points (puntos negros), lo que se considera como los datos que no quedaron en ninguno de los 239 clusters. Para la otra etiqueta tambien hay muchos Noise Points:\n",
    "\n",
    "<center><img src=\"PlotsDBScan/dbscan_etiqueta2_1.png\"></center>\n",
    "<center><small>Figura 11: Clustering por beer_beerid utilizando DBScan.</small></center>\n",
    "\n",
    "Como se puede ver, aunque se haya tomado menos del 10% de los datos, el algoritmo DBScan da buenos resultados, pero estos no se pueden comparar a los algoritmos anteriores ya que la cantidad de clusters es significativamente alta para ambas etiquetas. El problema es que DBScan es demasiado sensible al eps y min_samples, por lo tanto al aumentar el eps a un valor grande, la cantidad de clusters se reduce significativamente como en el siguiente ejemplo:\n",
    "\n",
    "<center><img src=\"PlotsDBScan/dbscan_etiqueta2_2.png\"></center>\n",
    "<center><small>Figura 12: Clustering por beer_beerid utilizando DBScan con eps = 50.</small></center>\n",
    "\n",
    "Al comparar lla figura 11 y 12 con etiqueta por *brewery_id*, al aumentar en magnitud 100 veces el eps, se logra reducir de 649 clusters a 271, esto demuestra la sensibilidad del algoritmo. Por otro lado los Noisy points se redujeron bastante respecto a la figura 11.\n",
    "\n",
    "Ahora, si el eps se disminuye un poco, tambien se nota la sensibilidad, como en la siguiente figura:\n",
    "\n",
    "<center><img src=\"PlotsDBScan/dbscan_etiqueta1_2.png\"></center>\n",
    "<center><small>Figura 13: Clustering por brewery_id utilizando DBScan con eps = 0.3.</small></center>\n",
    "\n",
    "Al comparar la figura 10 y 13 se puede notar que al modificar el eps de 0.5 a 0.3, se aumento de 239 a 606, demostrando nuevamente que el algoritmo es demasiado sensible al radio maximo dado por el eps.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "¿Qué atributo, Nombre de cervecería o Tipo de cerveza, describe mejor a los cluster como etiquetas\n",
    "de clase, según los resultados obtenidos previamente? ¿Hay mejores marcas que otras en\n",
    "relación a las evaluaciones obtenidas? ¿Se puede definir algún criterio para determinar el mejor\n",
    "tipo de cerveza? Comente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
